{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9277fde3",
   "metadata": {},
   "source": [
    "# ðŸš€ Deploy Policy with Observation Visualization\n",
    "\n",
    "This notebook deploys a trained policy to a physical robot while visualizing the observation data (images and state) before sending each action.\n",
    "\n",
    "### Features:\n",
    "- **Live Image Display**: Shows camera observations in real-time\n",
    "- **State Monitoring**: Displays robot state (joint positions, TCP poses, gripper states)\n",
    "- **Action Preview**: Shows predicted actions before sending to robot\n",
    "- **Debug-Friendly**: Great for understanding what the policy sees and predicts\n",
    "\n",
    "### Process:\n",
    "1. Configure deployment parameters\n",
    "2. Load the trained policy\n",
    "3. Set up visualization\n",
    "4. Run deployment loop with live observation display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11faae",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "First, specify the necessary parameters for deployment. **You must edit these values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# TODO: Change to the directory containing your trained policy checkpoint.\n",
    "# Example: \"outputs/2025-09-14/12-00-00\"\n",
    "CHECKPOINT_DIR = pathlib.Path(\"[TODO]\")\n",
    "\n",
    "# TODO: Change to the robot's IP address.\n",
    "SERVER_ENDPOINT = \"localhost:50051\"\n",
    "\n",
    "# Inference frequency in Hz. Lower values give more time to display visualizations.\n",
    "INFERENCE_FREQUENCY_HZ: float = 10.0\n",
    "\n",
    "# Visualization settings\n",
    "DISPLAY_IMAGES = True  # Set to False to only show state information\n",
    "IMAGE_SCALE = 0.5  # Scale factor for displayed images (0.5 = 50% size)\n",
    "\n",
    "print(f\"Attempting to load policy from: {CHECKPOINT_DIR}\")\n",
    "print(f\"Robot server endpoint: {SERVER_ENDPOINT}\")\n",
    "print(f\"Inference frequency: {INFERENCE_FREQUENCY_HZ} Hz\")\n",
    "print(f\"Display images: {DISPLAY_IMAGES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1951f7",
   "metadata": {},
   "source": [
    "## 2. Load the Policy\n",
    "\n",
    "Load the policy from the checkpoint directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_policies.robot_deploy.deploy_core import policy_loader\n",
    "\n",
    "policy, cfg = policy_loader.load_policy(CHECKPOINT_DIR)\n",
    "\n",
    "print(\"âœ… Policy loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac373be6",
   "metadata": {},
   "source": [
    "## 3. (Optional) Modify Policy Attributes\n",
    "\n",
    "Adjust policy settings if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the device on the config, not the policy!!\n",
    "cfg.device = \"cuda\"\n",
    "policy.to(cfg.device)  # or \"cpu\"\n",
    "\n",
    "print(f\"Device: {cfg.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d9c05",
   "metadata": {},
   "source": [
    "## 4. Setup Visualization Utilities\n",
    "\n",
    "Import visualization libraries and create helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f32897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "\n",
    "def display_observation(observation, action, step, clear=True):\n",
    "    \"\"\"Display observation images and state information.\"\"\"\n",
    "    if clear:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    # Extract image observations\n",
    "    image_keys = [k for k in observation.keys() if k.startswith('observation.image')]\n",
    "    \n",
    "    if DISPLAY_IMAGES and image_keys:\n",
    "        n_images = len(image_keys)\n",
    "        fig, axes = plt.subplots(1, n_images, figsize=(5*n_images*IMAGE_SCALE, 4*IMAGE_SCALE))\n",
    "        \n",
    "        if n_images == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, img_key in enumerate(sorted(image_keys)):\n",
    "            img_tensor = observation[img_key].squeeze(0)  # Remove batch dimension\n",
    "            \n",
    "            # Convert from CHW to HWC for display\n",
    "            if img_tensor.shape[0] in [1, 3]:  # Channel first\n",
    "                img_np = img_tensor.cpu().numpy().transpose(1, 2, 0)\n",
    "            else:\n",
    "                img_np = img_tensor.cpu().numpy()\n",
    "            \n",
    "            # Normalize if needed\n",
    "            if img_np.max() <= 1.0:\n",
    "                img_np = (img_np * 255).astype(np.uint8)\n",
    "            \n",
    "            axes[idx].imshow(img_np)\n",
    "            axes[idx].set_title(img_key.replace('observation.image.', ''))\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Display state information\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"STEP {step}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if 'observation.state' in observation:\n",
    "        state = observation['observation.state'].squeeze(0).cpu().numpy()\n",
    "        print(f\"\\nðŸ“Š STATE VECTOR (dim={len(state)}):\")\n",
    "        print(f\"  Values: {state[:10]}...\" if len(state) > 10 else f\"  Values: {state}\")\n",
    "        print(f\"  Min: {state.min():.4f}, Max: {state.max():.4f}, Mean: {state.mean():.4f}\")\n",
    "    \n",
    "    # Display predicted action\n",
    "    if action is not None:\n",
    "        action_np = action.squeeze(0).cpu().numpy()\n",
    "        print(f\"\\nðŸŽ¯ PREDICTED ACTION (dim={len(action_np)}):\")\n",
    "        print(f\"  Values: {action_np[:10]}...\" if len(action_np) > 10 else f\"  Values: {action_np}\")\n",
    "        print(f\"  Min: {action_np.min():.4f}, Max: {action_np.max():.4f}\")\n",
    "\n",
    "print(\"âœ… Visualization utilities ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655e0dd",
   "metadata": {},
   "source": [
    "## 5. Deploy to Robot with Visualization\n",
    "\n",
    "Execute the deployment loop with live observation display.\n",
    "\n",
    "âš ï¸ **Warning**: This will move the physical robot. Ensure the robot has a clear and safe workspace.\n",
    "\n",
    "The loop will:\n",
    "1. Capture current observation (images + state)\n",
    "2. Display the observation data\n",
    "3. Run policy inference to predict action\n",
    "4. **Wait for you to press ENTER**\n",
    "5. Send action to robot\n",
    "6. Repeat\n",
    "\n",
    "Press Ctrl+C in the kernel to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from example_policies.robot_deploy.deploy_core.deployment_structures import InferenceConfig\n",
    "from example_policies.robot_deploy.deploy_core.policy_manager import PolicyManager\n",
    "from example_policies.robot_deploy.robot_io.connection import RobotConnection\n",
    "from example_policies.robot_deploy.robot_io.robot_interface import RobotClient, RobotInterface\n",
    "\n",
    "# Load policy as a PolicyBundle\n",
    "policy_bundle = PolicyManager.load_single(CHECKPOINT_DIR, cfg.device)\n",
    "\n",
    "# Setup inference configuration\n",
    "config = InferenceConfig(\n",
    "    hz=INFERENCE_FREQUENCY_HZ,\n",
    "    device=cfg.device,\n",
    "    controller=RobotClient.CART_WAYPOINT,\n",
    ")\n",
    "\n",
    "# Run inference loop with visualization\n",
    "print(\"Starting inference loop with visualization... Press Ctrl+C to stop.\")\n",
    "with RobotConnection(SERVER_ENDPOINT) as stub:\n",
    "    robot_interface = RobotInterface(stub, policy_bundle.config)\n",
    "\n",
    "    # Move robot to home position before starting inference\n",
    "    print(\"Moving robot to home position...\")\n",
    "    robot_interface.move_home()\n",
    "    \n",
    "    step = 0\n",
    "    try:\n",
    "        while True:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Get observation\n",
    "            observation = robot_interface.get_observation(policy_bundle.config.device)\n",
    "            \n",
    "            if not observation:\n",
    "                time.sleep(1.0 / config.hz)\n",
    "                continue\n",
    "            \n",
    "            # Run policy inference\n",
    "            with torch.inference_mode():\n",
    "                action = policy_bundle.policy.select_action(observation)\n",
    "            \n",
    "            # Translate action to robot commands\n",
    "            action_translated = policy_bundle.translator.translate(action, observation)\n",
    "            \n",
    "            # Display observation and predicted action (without clearing)\n",
    "            display_observation(observation, action, step, clear=False)\n",
    "            \n",
    "            # Print translated action info\n",
    "            print(f\"\\nðŸ¤– READY TO SEND TO ROBOT:\")\n",
    "            print(f\"  Action mode: {policy_bundle.translator.action_mode}\")\n",
    "            print(f\"  Controller: {config.controller}\")\n",
    "            \n",
    "            # Wait for user confirmation\n",
    "            user_input = input(\"\\nâ¸ï¸  Press ENTER to send this action (or 'q' to quit)... \")\n",
    "            \n",
    "            if user_input.lower() == 'q':\n",
    "                print(\"Stopping deployment...\")\n",
    "                break\n",
    "            \n",
    "            # Send action to robot\n",
    "            robot_interface.send_action(\n",
    "                action_translated,\n",
    "                policy_bundle.translator.action_mode,\n",
    "                config.controller,\n",
    "            )\n",
    "            \n",
    "            print(\"âœ… Action sent!\")\n",
    "            \n",
    "            # Maintain frequency\n",
    "            elapsed = time.time() - start_time\n",
    "            sleep_time = (1.0 / config.hz) - elapsed\n",
    "            if sleep_time > 0:\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâœ… Deployment stopped by user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02e8e6",
   "metadata": {},
   "source": [
    "## 6. Additional Debugging Options\n",
    "\n",
    "You can modify the visualization function above or add additional debugging code here. For example:\n",
    "\n",
    "```python\n",
    "# Save observations to disk\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_observation_debug(observation, action, step, save_dir=\"./debug_observations\"):\n",
    "    import os\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save images\n",
    "    for img_key in observation.keys():\n",
    "        if img_key.startswith('observation.image'):\n",
    "            img = observation[img_key].squeeze(0).cpu().numpy()\n",
    "            if img.shape[0] in [1, 3]:\n",
    "                img = img.transpose(1, 2, 0)\n",
    "            Image.fromarray((img * 255).astype(np.uint8)).save(\n",
    "                f\"{save_dir}/step_{step:04d}_{img_key.replace('observation.image.', '')}.png\"\n",
    "            )\n",
    "    \n",
    "    # Save state and action\n",
    "    debug_data = {\n",
    "        'step': step,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'state': observation['observation.state'].cpu().numpy().tolist(),\n",
    "        'action': action.cpu().numpy().tolist()\n",
    "    }\n",
    "    \n",
    "    with open(f\"{save_dir}/step_{step:04d}_data.json\", 'w') as f:\n",
    "        json.dump(debug_data, f, indent=2)\n",
    "```\n",
    "\n",
    "You can then call `save_observation_debug(observation, action, step)` in the deployment loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.5 (hackathon-example-policies)",
   "language": "python",
   "name": "hackathon-example-policies"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
