{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa93b9d1",
   "metadata": {},
   "source": [
    "# üöÄ Deploy a Trained Policy\n",
    "\n",
    "This notebook guides you through deploying a trained policy to a physical robot. \n",
    "\n",
    "### Process:\n",
    "1.  **Configure**: Set the path to your trained model and the robot's server address.\n",
    "2.  **Load**: The `policy_loader` automatically loads the model and its training configuration.\n",
    "3.  **Deploy**: The `deploy_policy` function starts the inference loop and sends commands to the robot.\n",
    "\n",
    "The deployment script automatically handles details like the action space (`tcp`, `joint`, etc.) based on the loaded training configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596978f",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "First, specify the necessary parameters for deployment. **You must edit these values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# TODO: Change to the directory containing your trained policy checkpoint.\n",
    "# Example: \"outputs/2025-09-14/12-00-00\"\n",
    "CHECKPOINT_DIR = pathlib.Path(\"outputs/<policy_checkpoint_dir>\")\n",
    "\n",
    "# TODO: Change to the robot's IP address.\n",
    "SERVER_ENDPOINT = \"<robot_ip_address>:50051\"\n",
    "\n",
    "# Inference frequency in Hz. Higher values result in smoother but potentially faster movements.\n",
    "INFERENCE_FREQUENCY_HZ: float = 5.0\n",
    "\n",
    "print(f\"Attempting to load policy from: {CHECKPOINT_DIR}\")\n",
    "print(f\"Robot server endpoint: {SERVER_ENDPOINT}\")\n",
    "print(f\"Inference frequency: {INFERENCE_FREQUENCY_HZ} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6129b",
   "metadata": {},
   "source": [
    "## 2. Load the Policy\n",
    "\n",
    "Now, we load the policy from the specified checkpoint directory. The loader will find the latest checkpoint and its corresponding configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855477b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from example_policies.robot_deploy.deploy_core.policy_manager import PolicyManager\n",
    "\n",
    "# Select device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the policy bundle (includes policy, config, translator, printer)\n",
    "policy_bundle = PolicyManager.load_single(CHECKPOINT_DIR, device)\n",
    "\n",
    "print(\"‚úÖ Policy loaded successfully!\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Termination signal support: {policy_bundle.has_termination}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3740f5",
   "metadata": {},
   "source": [
    "## 3. Verify Policy Configuration\n",
    "\n",
    "Verify the loaded policy configuration matches your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify loaded policy configuration\n",
    "cfg = policy_bundle.config\n",
    "\n",
    "print(f\"Policy type: {cfg.type}\")\n",
    "print(f\"Input features: {list(cfg.input_features.keys())}\")\n",
    "print(f\"Output features: {list(cfg.output_features.keys())}\")\n",
    "print(f\"Action shape: {cfg.output_features['action'].shape}\")\n",
    "\n",
    "if hasattr(cfg, 'metadata') and cfg.metadata:\n",
    "    print(f\"\\nAction names: {cfg.metadata['features']['action']['names']}\")\n",
    "    print(f\"State names: {cfg.metadata['features']['observation.state']['names']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fa971",
   "metadata": {},
   "source": [
    "## 4. Deploy to Robot\n",
    "\n",
    "Finally, execute the cell below to start sending commands to the robot.\n",
    "\n",
    "‚ö†Ô∏è **Warning**: This will move the physical robot. Ensure the robot has a clear and safe workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_policies.robot_deploy.deploy_core.deployment_structures import InferenceConfig\n",
    "from example_policies.robot_deploy.deploy_core.inference_runner import InferenceRunner\n",
    "from example_policies.robot_deploy.robot_io.connection import RobotConnection\n",
    "from example_policies.robot_deploy.robot_io.robot_interface import RobotClient, RobotInterface\n",
    "\n",
    "# Setup inference configuration\n",
    "config = InferenceConfig(\n",
    "    hz=INFERENCE_FREQUENCY_HZ,\n",
    "    device=device,\n",
    "    controller=RobotClient.CART_WAYPOINT,  # Most stable and responsive\n",
    ")\n",
    "\n",
    "# Run inference loop\n",
    "print(\"Starting inference loop...\")\n",
    "print(f\"  Frequency: {INFERENCE_FREQUENCY_HZ} Hz\")\n",
    "print(f\"  Controller: CART_WAYPOINT\")\n",
    "\n",
    "with RobotConnection(SERVER_ENDPOINT) as stub:\n",
    "    robot_interface = RobotInterface(stub, policy_bundle.config)\n",
    "    runner = InferenceRunner(robot_interface, config)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            termination = runner.run_step(policy_bundle)\n",
    "            # Optionally handle termination signal\n",
    "            # if termination is not None and termination > 0.5:\n",
    "            #     print(\"Termination signal received!\")\n",
    "            #     break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è Inference stopped by user\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon_example_policies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
