{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Model Training\n",
    "\n",
    "This notebook guides you through the process of training a policy on your converted dataset. \n",
    "\n",
    "The process is broken down into a few simple steps:\n",
    "1.  **Setup**: Apply necessary patches to the `lerobot` library.\n",
    "2.  **Dataset**: Specify the path to your training data.\n",
    "3.  **Configuration**: Select a model architecture and its hyperparameters.\n",
    "4.  **Training**: Launch the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 1. Setup\n",
    "\n",
    "First, apply our custom patches to the `lerobot` library. This only needs to be done once per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables BEFORE any imports\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"LEROBOT_VIDEO_BACKEND\"] = \"pyav\"\n",
    "\n",
    "# Suppress torchvision video deprecation warning\n",
    "warnings.filterwarnings(\"ignore\", message=\".*video decoding and encoding capabilities.*\")\n",
    "\n",
    "from example_policies import lerobot_patches\n",
    "\n",
    "lerobot_patches.apply_patches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 2. Select Dataset\n",
    "\n",
    "> **Action Required:** Update `DATA_DIR` to point to the dataset you created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# TODO: Set the path to your converted dataset directory.\n",
    "DATA_DIR = pathlib.Path(\"/data/[TODO]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 3. Select Model Configuration\n",
    "\n",
    "We provide several pre-made configurations as a starting point, but recommend using dif_flow_config. You can also adjust parameters like `batch_size` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one of the following configurations\n",
    "from example_policies.config_factory import diffusion_config, dit_flow_config\n",
    "\n",
    "cfg = dit_flow_config(DATA_DIR, enable_wandb=False)\n",
    "\n",
    "# Disable multiprocessing if there are issues with dataloader workers\n",
    "# cfg.num_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify additional keywords by looking at the lerobot configuration code, e.g. `lerobot.policies.act.configuration_act`\n",
    "and then adapt the code cell accordingly:\n",
    "```python\n",
    "cfg = act_config(DATA_DIR, policy_kwargs={\n",
    "    optimizer_lr=1e-5\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 4. Start Training\n",
    "\n",
    "This cell will start the training process. Metrics and logs will be streamed to the console, and if you have configured it, to Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_policies.train import train\n",
    "\n",
    "# Set video backend in config\n",
    "cfg.dataset.video_backend = \"pyav\"\n",
    "\n",
    "train(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-example-policies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
