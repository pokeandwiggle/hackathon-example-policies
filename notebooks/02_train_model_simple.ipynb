{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Model Training\n",
    "\n",
    "This notebook guides you through the process of training a policy on your converted dataset. \n",
    "\n",
    "The process is broken down into a few simple steps:\n",
    "1.  **Setup**: Apply necessary patches to the `lerobot` library.\n",
    "2.  **Dataset**: Specify the path to your training data.\n",
    "3.  **Configuration**: Select a model architecture and its hyperparameters.\n",
    "4.  **Training**: Launch the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 1. Setup\n",
    "\n",
    "First, apply our custom patches to the `lerobot` library. This only needs to be done once per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables BEFORE any imports\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"LEROBOT_VIDEO_BACKEND\"] = \"pyav\"\n",
    "\n",
    "# Suppress torchvision video deprecation warning\n",
    "warnings.filterwarnings(\"ignore\", message=\".*video decoding and encoding capabilities.*\")\n",
    "\n",
    "from example_policies import lerobot_patches\n",
    "\n",
    "lerobot_patches.apply_patches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 2. Select Dataset\n",
    "\n",
    "> **Action Required:** Update `DATA_DIR` to point to the dataset you created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# TODO: Set the path to your converted dataset directory.\n",
    "DATA_DIR = pathlib.Path(\"/home/yizhang/Projects/hackathon-ki-fabrik/data/sort_red_blocks_80_old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 3. Select Model Configuration\n",
    "\n",
    "We provide several pre-made configurations as a starting point, but recommend using dif_flow_config. You can also adjust parameters like `batch_size` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Training by epochs:\n",
      "   - Dataset size: 21308 frames\n",
      "   - Batch size: 64\n",
      "   - Epochs: 200\n",
      "   - Calculated steps: 66400\n",
      "   - Save every: 100 epochs (33200 steps)\n",
      "\n",
      "Final Training Configuration (full details):\n",
      "TrainPipelineConfig(dataset=DatasetConfig(repo_id='sort_red_blocks_80',\n",
      "                                          root=PosixPath('/data/sort_red_blocks_80'),\n",
      "                                          episodes=[0,\n",
      "                                                    1,\n",
      "                                                    2,\n",
      "                                                    3,\n",
      "                                                    4,\n",
      "                                                    5,\n",
      "                                                    6,\n",
      "                                                    7,\n",
      "                                                    8,\n",
      "                                                    9,\n",
      "                                                    10,\n",
      "                                                    11,\n",
      "                                                    12,\n",
      "                                                    13,\n",
      "                                                    14,\n",
      "                                                    15,\n",
      "                                                    16,\n",
      "                                                    17,\n",
      "                                                    18,\n",
      "                                                    19,\n",
      "                                                    20,\n",
      "                                                    21,\n",
      "                                                    22,\n",
      "                                                    23,\n",
      "                                                    24,\n",
      "                                                    25,\n",
      "                                                    26,\n",
      "                                                    27,\n",
      "                                                    28,\n",
      "                                                    29,\n",
      "                                                    30,\n",
      "                                                    31,\n",
      "                                                    32,\n",
      "                                                    33,\n",
      "                                                    34,\n",
      "                                                    35,\n",
      "                                                    36,\n",
      "                                                    37,\n",
      "                                                    38,\n",
      "                                                    39,\n",
      "                                                    40,\n",
      "                                                    41,\n",
      "                                                    42,\n",
      "                                                    43,\n",
      "                                                    44,\n",
      "                                                    45,\n",
      "                                                    46,\n",
      "                                                    47,\n",
      "                                                    48,\n",
      "                                                    49,\n",
      "                                                    50,\n",
      "                                                    51,\n",
      "                                                    52,\n",
      "                                                    53,\n",
      "                                                    54,\n",
      "                                                    55,\n",
      "                                                    56,\n",
      "                                                    57,\n",
      "                                                    58,\n",
      "                                                    59,\n",
      "                                                    60,\n",
      "                                                    61,\n",
      "                                                    62,\n",
      "                                                    63,\n",
      "                                                    64,\n",
      "                                                    65,\n",
      "                                                    66,\n",
      "                                                    67,\n",
      "                                                    68,\n",
      "                                                    69,\n",
      "                                                    70,\n",
      "                                                    71,\n",
      "                                                    72,\n",
      "                                                    73,\n",
      "                                                    74,\n",
      "                                                    75,\n",
      "                                                    76,\n",
      "                                                    77,\n",
      "                                                    78,\n",
      "                                                    79,\n",
      "                                                    80,\n",
      "                                                    81],\n",
      "                                          image_transforms=ImageTransformsConfig(enable=False,\n",
      "                                                                                 max_num_transforms=3,\n",
      "                                                                                 random_order=False,\n",
      "                                                                                 tfs={'brightness': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                         type='ColorJitter',\n",
      "                                                                                                                         kwargs={'brightness': (0.8,\n",
      "                                                                                                                                                1.2)}),\n",
      "                                                                                      'contrast': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                       type='ColorJitter',\n",
      "                                                                                                                       kwargs={'contrast': (0.8,\n",
      "                                                                                                                                            1.2)}),\n",
      "                                                                                      'hue': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                  type='ColorJitter',\n",
      "                                                                                                                  kwargs={'hue': (-0.05,\n",
      "                                                                                                                                  0.05)}),\n",
      "                                                                                      'saturation': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                         type='ColorJitter',\n",
      "                                                                                                                         kwargs={'saturation': (0.5,\n",
      "                                                                                                                                                1.5)}),\n",
      "                                                                                      'sharpness': ImageTransformConfig(weight=1.0,\n",
      "                                                                                                                        type='SharpnessJitter',\n",
      "                                                                                                                        kwargs={'sharpness': (0.5,\n",
      "                                                                                                                                              1.5)})}),\n",
      "                                          revision=None,\n",
      "                                          use_imagenet_stats=True,\n",
      "                                          video_backend='torchcodec'),\n",
      "                    env=None,\n",
      "                    policy=DiTFlowImageConfig(n_obs_steps=2,\n",
      "                                              normalization_mapping={'ACTION': <NormalizationMode.MIN_MAX: 'MIN_MAX'>,\n",
      "                                                                     'STATE': <NormalizationMode.MIN_MAX: 'MIN_MAX'>,\n",
      "                                                                     'VISUAL': <NormalizationMode.MEAN_STD: 'MEAN_STD'>},\n",
      "                                              input_features={},\n",
      "                                              output_features={},\n",
      "                                              device='cuda',\n",
      "                                              use_amp=False,\n",
      "                                              push_to_hub=False,\n",
      "                                              repo_id=None,\n",
      "                                              private=None,\n",
      "                                              tags=None,\n",
      "                                              license=None,\n",
      "                                              horizon=16,\n",
      "                                              n_action_steps=8,\n",
      "                                              drop_n_last_frames=7,\n",
      "                                              vision_backbone='resnet18',\n",
      "                                              crop_shape=(224, 224),\n",
      "                                              crop_is_random=True,\n",
      "                                              pretrained_backbone_weights=None,\n",
      "                                              use_group_norm=True,\n",
      "                                              spatial_softmax_num_keypoints=32,\n",
      "                                              use_separate_rgb_encoder_per_camera=True,\n",
      "                                              frequency_embedding_dim=256,\n",
      "                                              hidden_dim=512,\n",
      "                                              num_blocks=6,\n",
      "                                              num_heads=16,\n",
      "                                              dropout=0.1,\n",
      "                                              dim_feedforward=4096,\n",
      "                                              activation='gelu',\n",
      "                                              training_noise_sampling='uniform',\n",
      "                                              clip_sample=True,\n",
      "                                              clip_sample_range=1.0,\n",
      "                                              num_inference_steps=100,\n",
      "                                              do_mask_loss_for_padding=False,\n",
      "                                              optimizer_lr=0.0002,\n",
      "                                              optimizer_betas=(0.95, 0.999),\n",
      "                                              optimizer_eps=1e-08,\n",
      "                                              optimizer_weight_decay=1e-06,\n",
      "                                              scheduler_name='cosine',\n",
      "                                              scheduler_warmup_steps=500),\n",
      "                    output_dir=None,\n",
      "                    job_name=None,\n",
      "                    resume=False,\n",
      "                    seed=1000,\n",
      "                    num_workers=0,\n",
      "                    batch_size=64,\n",
      "                    steps=66400,\n",
      "                    eval_freq=20000,\n",
      "                    log_freq=200,\n",
      "                    save_checkpoint=True,\n",
      "                    save_freq=33200,\n",
      "                    use_policy_training_preset=True,\n",
      "                    optimizer=None,\n",
      "                    scheduler=None,\n",
      "                    eval=EvalConfig(n_episodes=50,\n",
      "                                    batch_size=50,\n",
      "                                    use_async_envs=False),\n",
      "                    wandb=WandBConfig(enable=False,\n",
      "                                      disable_artifact=True,\n",
      "                                      project='lerobot',\n",
      "                                      entity=None,\n",
      "                                      notes=None,\n",
      "                                      run_id=None,\n",
      "                                      mode=None))\n"
     ]
    }
   ],
   "source": [
    "# Select one of the following configurations\n",
    "from example_policies.config_factory import diffusion_config, dit_flow_config, dit_flow_image_config\n",
    "\n",
    "# cfg = dit_flow_config(DATA_DIR, enable_wandb=False)\n",
    "cfg = dit_flow_image_config(DATA_DIR, enable_wandb=False)\n",
    "\n",
    "# Disable multiprocessing if there are issues with dataloader workers\n",
    "# cfg.num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.log_freq = 1\n",
    "cfg.save_freq = 10000\n",
    "cfg.steps = 80000\n",
    "\n",
    "\n",
    "cfg.policy.optimizer_lr = 2e-4\n",
    "\n",
    "cfg.job_name = \"ditflow_sort_red_blocks_80\"\n",
    "cfg.output_dir = pathlib.Path(\"/home/yizhang/Projects/hackathon-ki-fabrik/outputs/ditflow_sort_red_blocks_80\")\n",
    "cfg.wandb.enable = True\n",
    "cfg.wandb.project = \"paper\"\n",
    "cfg.wandb.entity = \"470620104-technical-university-of-munich\"\n",
    "\n",
    "import json\n",
    "\n",
    "print(json.dumps(cfg.to_dict(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify additional keywords by looking at the lerobot configuration code, e.g. `lerobot.policies.act.configuration_act`\n",
    "and then adapt the code cell accordingly:\n",
    "```python\n",
    "cfg = act_config(DATA_DIR, policy_kwargs={\n",
    "    optimizer_lr=1e-5\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'repo_id': 'sort_red_blocks_80', 'root': '/data/sort_red_blocks_80', 'episodes': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81], 'image_transforms': {'enable': False, 'max_num_transforms': 3, 'random_order': False, 'tfs': {'brightness': {'weight': 1.0, 'type': 'ColorJitter', 'kwargs': {'brightness': [0.8, 1.2]}}, 'contrast': {'weight': 1.0, 'type': 'ColorJitter', 'kwargs': {'contrast': [0.8, 1.2]}}, 'saturation': {'weight': 1.0, 'type': 'ColorJitter', 'kwargs': {'saturation': [0.5, 1.5]}}, 'hue': {'weight': 1.0, 'type': 'ColorJitter', 'kwargs': {'hue': [-0.05, 0.05]}}, 'sharpness': {'weight': 1.0, 'type': 'SharpnessJitter', 'kwargs': {'sharpness': [0.5, 1.5]}}}}, 'revision': None, 'use_imagenet_stats': True, 'video_backend': 'torchcodec'}, 'env': None, 'policy': {'type': 'ditflow_image', 'n_obs_steps': 2, 'normalization_mapping': {'VISUAL': <NormalizationMode.MEAN_STD: 'MEAN_STD'>, 'STATE': <NormalizationMode.MIN_MAX: 'MIN_MAX'>, 'ACTION': <NormalizationMode.MIN_MAX: 'MIN_MAX'>}, 'input_features': {}, 'output_features': {}, 'device': 'cuda', 'use_amp': False, 'push_to_hub': False, 'repo_id': None, 'private': None, 'tags': None, 'license': None, 'horizon': 16, 'n_action_steps': 8, 'drop_n_last_frames': 7, 'vision_backbone': 'resnet18', 'crop_shape': [224, 224], 'crop_is_random': True, 'pretrained_backbone_weights': None, 'use_group_norm': True, 'spatial_softmax_num_keypoints': 32, 'use_separate_rgb_encoder_per_camera': True, 'frequency_embedding_dim': 256, 'hidden_dim': 512, 'num_blocks': 6, 'num_heads': 16, 'dropout': 0.1, 'dim_feedforward': 4096, 'activation': 'gelu', 'training_noise_sampling': 'uniform', 'clip_sample': True, 'clip_sample_range': 1.0, 'num_inference_steps': 100, 'do_mask_loss_for_padding': False, 'optimizer_lr': 0.0002, 'optimizer_betas': [0.95, 0.999], 'optimizer_eps': 1e-08, 'optimizer_weight_decay': 1e-06, 'scheduler_name': 'cosine', 'scheduler_warmup_steps': 500}, 'output_dir': '/home/jovyan/outputs/ditflow_image_sort_red_blocks_80', 'job_name': 'ditflow_image_sort_red_blocks_80', 'resume': False, 'seed': 1000, 'num_workers': 0, 'batch_size': 32, 'steps': 20000, 'eval_freq': 20000, 'log_freq': 100, 'save_checkpoint': True, 'save_freq': 5000, 'use_policy_training_preset': True, 'optimizer': None, 'scheduler': None, 'eval': {'n_episodes': 50, 'batch_size': 50, 'use_async_envs': False}, 'wandb': {'enable': True, 'disable_artifact': True, 'project': 'paper', 'entity': '470620104-technical-university-of-munich', 'notes': None, 'run_id': None, 'mode': None}}\n"
     ]
    }
   ],
   "source": [
    "# cfg.steps = \n",
    "\n",
    "cfg.job_name = \"ditflow_image_sort_red_blocks_80\" # \"ditflow_sort_red_blocks_80\"\n",
    "cfg.output_dir = pathlib.Path(\"/home/jovyan/outputs/ditflow_image_sort_red_blocks_80/\")\n",
    "cfg.save_freq = 5000\n",
    "cfg.steps = 20000\n",
    "cfg.log_freq = 100\n",
    "\n",
    "cfg.batch_size = 32\n",
    "\n",
    "cfg.wandb.enable = True\n",
    "cfg.wandb.project = \"paper\"\n",
    "cfg.wandb.entity = \"470620104-technical-university-of-munich\"\n",
    "\n",
    "print(cfg.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 4. Start Training\n",
    "\n",
    "This cell will start the training process. Metrics and logs will be streamed to the console, and if you have configured it, to Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-12-03 10:14:08 ts/train.py:111 {'batch_size': 32,\n",
      " 'dataset': {'episodes': [0,\n",
      "                          1,\n",
      "                          2,\n",
      "                          3,\n",
      "                          4,\n",
      "                          5,\n",
      "                          6,\n",
      "                          7,\n",
      "                          8,\n",
      "                          9,\n",
      "                          10,\n",
      "                          11,\n",
      "                          12,\n",
      "                          13,\n",
      "                          14,\n",
      "                          15,\n",
      "                          16,\n",
      "                          17,\n",
      "                          18,\n",
      "                          19,\n",
      "                          20,\n",
      "                          21,\n",
      "                          22,\n",
      "                          23,\n",
      "                          24,\n",
      "                          25,\n",
      "                          26,\n",
      "                          27,\n",
      "                          28,\n",
      "                          29,\n",
      "                          30,\n",
      "                          31,\n",
      "                          32,\n",
      "                          33,\n",
      "                          34,\n",
      "                          35,\n",
      "                          36,\n",
      "                          37,\n",
      "                          38,\n",
      "                          39,\n",
      "                          40,\n",
      "                          41,\n",
      "                          42,\n",
      "                          43,\n",
      "                          44,\n",
      "                          45,\n",
      "                          46,\n",
      "                          47,\n",
      "                          48,\n",
      "                          49,\n",
      "                          50,\n",
      "                          51,\n",
      "                          52,\n",
      "                          53,\n",
      "                          54,\n",
      "                          55,\n",
      "                          56,\n",
      "                          57,\n",
      "                          58,\n",
      "                          59,\n",
      "                          60,\n",
      "                          61,\n",
      "                          62,\n",
      "                          63,\n",
      "                          64,\n",
      "                          65,\n",
      "                          66,\n",
      "                          67,\n",
      "                          68,\n",
      "                          69,\n",
      "                          70,\n",
      "                          71,\n",
      "                          72,\n",
      "                          73,\n",
      "                          74,\n",
      "                          75,\n",
      "                          76,\n",
      "                          77,\n",
      "                          78,\n",
      "                          79,\n",
      "                          80,\n",
      "                          81],\n",
      "             'image_transforms': {'enable': False,\n",
      "                                  'max_num_transforms': 3,\n",
      "                                  'random_order': False,\n",
      "                                  'tfs': {'brightness': {'kwargs': {'brightness': [0.8,\n",
      "                                                                                   1.2]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'contrast': {'kwargs': {'contrast': [0.8,\n",
      "                                                                               1.2]},\n",
      "                                                       'type': 'ColorJitter',\n",
      "                                                       'weight': 1.0},\n",
      "                                          'hue': {'kwargs': {'hue': [-0.05,\n",
      "                                                                     0.05]},\n",
      "                                                  'type': 'ColorJitter',\n",
      "                                                  'weight': 1.0},\n",
      "                                          'saturation': {'kwargs': {'saturation': [0.5,\n",
      "                                                                                   1.5]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'sharpness': {'kwargs': {'sharpness': [0.5,\n",
      "                                                                                 1.5]},\n",
      "                                                        'type': 'SharpnessJitter',\n",
      "                                                        'weight': 1.0}}},\n",
      "             'repo_id': 'sort_red_blocks_80',\n",
      "             'revision': None,\n",
      "             'root': '/data/sort_red_blocks_80',\n",
      "             'use_imagenet_stats': True,\n",
      "             'video_backend': 'pyav'},\n",
      " 'env': None,\n",
      " 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},\n",
      " 'eval_freq': 20000,\n",
      " 'job_name': 'ditflow_image_sort_red_blocks_80',\n",
      " 'log_freq': 100,\n",
      " 'num_workers': 0,\n",
      " 'optimizer': {'betas': [0.95, 0.999],\n",
      "               'eps': 1e-08,\n",
      "               'grad_clip_norm': 10.0,\n",
      "               'lr': 0.0002,\n",
      "               'type': 'adam',\n",
      "               'weight_decay': 1e-06},\n",
      " 'output_dir': '/home/jovyan/outputs/ditflow_image_sort_red_blocks_80',\n",
      " 'policy': {'activation': 'gelu',\n",
      "            'clip_sample': True,\n",
      "            'clip_sample_range': 1.0,\n",
      "            'crop_is_random': True,\n",
      "            'crop_shape': [224, 224],\n",
      "            'device': 'cuda',\n",
      "            'dim_feedforward': 4096,\n",
      "            'do_mask_loss_for_padding': False,\n",
      "            'drop_n_last_frames': 7,\n",
      "            'dropout': 0.1,\n",
      "            'frequency_embedding_dim': 256,\n",
      "            'hidden_dim': 512,\n",
      "            'horizon': 16,\n",
      "            'input_features': {},\n",
      "            'license': None,\n",
      "            'n_action_steps': 8,\n",
      "            'n_obs_steps': 2,\n",
      "            'normalization_mapping': {'ACTION': <NormalizationMode.MIN_MAX: 'MIN_MAX'>,\n",
      "                                      'STATE': <NormalizationMode.MIN_MAX: 'MIN_MAX'>,\n",
      "                                      'VISUAL': <NormalizationMode.MEAN_STD: 'MEAN_STD'>},\n",
      "            'num_blocks': 6,\n",
      "            'num_heads': 16,\n",
      "            'num_inference_steps': 100,\n",
      "            'optimizer_betas': [0.95, 0.999],\n",
      "            'optimizer_eps': 1e-08,\n",
      "            'optimizer_lr': 0.0002,\n",
      "            'optimizer_weight_decay': 1e-06,\n",
      "            'output_features': {},\n",
      "            'pretrained_backbone_weights': None,\n",
      "            'private': None,\n",
      "            'push_to_hub': False,\n",
      "            'repo_id': None,\n",
      "            'scheduler_name': 'cosine',\n",
      "            'scheduler_warmup_steps': 500,\n",
      "            'spatial_softmax_num_keypoints': 32,\n",
      "            'tags': None,\n",
      "            'training_noise_sampling': 'uniform',\n",
      "            'type': 'ditflow_image',\n",
      "            'use_amp': False,\n",
      "            'use_group_norm': True,\n",
      "            'use_separate_rgb_encoder_per_camera': True,\n",
      "            'vision_backbone': 'resnet18'},\n",
      " 'resume': False,\n",
      " 'save_checkpoint': True,\n",
      " 'save_freq': 5000,\n",
      " 'scheduler': {'name': 'cosine', 'num_warmup_steps': 500, 'type': 'diffuser'},\n",
      " 'seed': 1000,\n",
      " 'steps': 20000,\n",
      " 'use_policy_training_preset': True,\n",
      " 'wandb': {'disable_artifact': True,\n",
      "           'enable': True,\n",
      "           'entity': '470620104-technical-university-of-munich',\n",
      "           'mode': None,\n",
      "           'notes': None,\n",
      "           'project': 'paper',\n",
      "           'run_id': None}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "INFO 2025-12-03 10:14:10 _patches.py:128 Track this run --> \u001b[1m\u001b[33mhttps://wandb.ai/470620104-technical-university-of-munich/paper/runs/5j26axxl\u001b[0m\n",
      "INFO 2025-12-03 10:14:10 ts/train.py:127 Creating dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mLogs will be synced with wandb.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6247079302564da18e2531cc1fc174ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-12-03 10:14:10 ts/train.py:138 Creating policy\n",
      "INFO 2025-12-03 10:14:11 ts/train.py:144 Creating optimizer and scheduler\n",
      "INFO 2025-12-03 10:14:11 ts/train.py:156 \u001b[1m\u001b[33mOutput dir:\u001b[0m /home/jovyan/outputs/ditflow_image_sort_red_blocks_80\n",
      "INFO 2025-12-03 10:14:11 ts/train.py:159 cfg.steps=20000 (20K)\n",
      "INFO 2025-12-03 10:14:11 ts/train.py:160 dataset.num_frames=21308 (21K)\n",
      "INFO 2025-12-03 10:14:11 ts/train.py:161 dataset.num_episodes=82\n",
      "INFO 2025-12-03 10:14:11 ts/train.py:162 num_learnable_params=75699491 (76M)\n",
      "INFO 2025-12-03 10:14:11 ts/train.py:163 num_total_params=75699741 (76M)\n",
      "INFO 2025-12-03 10:14:11 ts/train.py:202 Start offline training on a fixed dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flow params: 42.11M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-12-03 10:15:26 ts/train.py:232 step:100 smpl:3K ep:12 epch:0.15 loss:1.224 grdn:0.997 lr:2.0e-05 updt_s:0.075 data_s:0.677\n"
     ]
    }
   ],
   "source": [
    "from example_policies.train import train\n",
    "\n",
    "# Set video backend in config\n",
    "cfg.dataset.video_backend = \"pyav\"\n",
    "\n",
    "train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload policy to hub\n",
    "\n",
    "!hf upload --repo-type model continuallearning/ditflow_sort_red_blocks_80 /home/yizhang/Projects/hackathon-ki-fabrik/outputs/ditflow_sort_red_blocks_80/checkpoints/last/pretrained_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
