{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6a7d30",
   "metadata": {},
   "source": [
    "# ü§ñ Deploy Policy from Dataset Observations\n",
    "\n",
    "This notebook runs the trained policy using **observations from a training episode** and sends the predicted actions to the robot.\n",
    "\n",
    "This is useful for:\n",
    "1. Testing if the policy produces reasonable actions from known observations\n",
    "2. Debugging deployment issues without needing live sensor data\n",
    "3. Replaying a demonstration with learned actions\n",
    "\n",
    "‚ö†Ô∏è **Warning**: This will move the physical robot! Ensure the workspace is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf18e2",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set paths and deployment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec63ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# TODO: Set these paths\n",
    "CHECKPOINT_DIR = Path(\"outputs/train/006200/pretrained_model\")\n",
    "\n",
    "# Dataset path - try multiple locations\n",
    "possible_dataset_paths = [\n",
    "    Path(\"/data/single_stack_demo\"),  # JupyterHub absolute\n",
    "    Path(\"../../data/single_stack_demo\"),  # JupyterHub relative\n",
    "    Path(\"../data/single_stack_demo\"),  # Local\n",
    "    Path(\"../data/lerobot_output\"),  # Local alternative\n",
    "]\n",
    "\n",
    "DATASET_DIR = None\n",
    "for p in possible_dataset_paths:\n",
    "    if p.exists():\n",
    "        DATASET_DIR = p\n",
    "        print(f\"‚úÖ Found dataset at: {p}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"‚ùå Not found: {p}\")\n",
    "\n",
    "if DATASET_DIR is None:\n",
    "    print(\"\\n‚ö†Ô∏è Please set DATASET_DIR manually\")\n",
    "\n",
    "# Robot connection\n",
    "SERVER_ENDPOINT = \"<robot_ip_address>:50051\"  # TODO: Set robot IP\n",
    "\n",
    "# Episode to replay\n",
    "EPISODE_INDEX = 0\n",
    "\n",
    "# Inference frequency (Hz) - controls how fast actions are sent\n",
    "INFERENCE_FREQUENCY_HZ = 10.0\n",
    "\n",
    "print(f\"\\nCheckpoint: {CHECKPOINT_DIR}\")\n",
    "print(f\"Dataset: {DATASET_DIR}\")\n",
    "print(f\"Episode: {EPISODE_INDEX}\")\n",
    "print(f\"Robot server: {SERVER_ENDPOINT}\")\n",
    "print(f\"Frequency: {INFERENCE_FREQUENCY_HZ} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c76c8",
   "metadata": {},
   "source": [
    "## 2. Load Policy and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c34ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "from example_policies.robot_deploy.deploy_core.policy_loader import load_policy\n",
    "\n",
    "# Select device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load policy\n",
    "policy, cfg = load_policy(CHECKPOINT_DIR)\n",
    "cfg.device = device\n",
    "policy.to(device)\n",
    "policy.eval()\n",
    "print(f\"‚úÖ Policy loaded\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = LeRobotDataset(\n",
    "    repo_id=str(DATASET_DIR),\n",
    "    root=DATASET_DIR,\n",
    ")\n",
    "print(f\"‚úÖ Dataset loaded: {len(dataset)} frames\")\n",
    "\n",
    "# Get episode info\n",
    "all_episodes = sorted(dataset.meta.episodes.keys())\n",
    "print(f\"Available episodes: {all_episodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11203797",
   "metadata": {},
   "source": [
    "## 3. Prepare Episode Data\n",
    "\n",
    "Get the frame indices for the selected episode (memory efficient - don't load data yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06168e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def to_device_batch(batch: dict, device: torch.device, non_blocking: bool = True):\n",
    "    \"\"\"Move all tensors in a batch to the specified device.\"\"\"\n",
    "    out = {}\n",
    "    for k, v in batch.items():\n",
    "        if torch.is_tensor(v):\n",
    "            out[k] = v.to(device, non_blocking=non_blocking)\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "# Load episode metadata from JSON (no heavy data)\n",
    "episodes_json = DATASET_DIR / \"meta\" / \"episodes.jsonl\"\n",
    "episodes = []\n",
    "with open(episodes_json, \"r\") as f:\n",
    "    for line in f:\n",
    "        episodes.append(json.loads(line))\n",
    "\n",
    "# Get episode info\n",
    "episode_info = episodes[EPISODE_INDEX]\n",
    "episode_length = episode_info[\"length\"]\n",
    "\n",
    "# Calculate starting index by summing lengths of all previous episodes\n",
    "episode_start_idx = 0\n",
    "for ep_idx in range(EPISODE_INDEX):\n",
    "    episode_start_idx += episodes[ep_idx][\"length\"]\n",
    "\n",
    "# Create list of dataset indices for this episode\n",
    "episode_indices = list(range(episode_start_idx, episode_start_idx + episode_length))\n",
    "\n",
    "# Verify parquet file exists\n",
    "parquet_path = DATASET_DIR / f\"data/chunk-000/episode_{EPISODE_INDEX:06d}.parquet\"\n",
    "assert parquet_path.exists(), f\"Parquet file not found: {parquet_path}\"\n",
    "\n",
    "# Verify video files exist\n",
    "video_keys = [\"observation.images.rgb_static\", \"observation.images.rgb_left\", \"observation.images.rgb_right\"]\n",
    "for key in video_keys:\n",
    "    video_path = DATASET_DIR / f\"videos/chunk-000/{key}/episode_{EPISODE_INDEX:06d}.mp4\"\n",
    "    if video_path.exists():\n",
    "        print(f\"‚úÖ Video: {key}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Video not found: {key}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Episode {EPISODE_INDEX}: {episode_length} frames\")\n",
    "print(f\"   Dataset indices: {episode_start_idx} to {episode_start_idx + episode_length - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9465d9",
   "metadata": {},
   "source": [
    "## 4. Preview Actions (Dry Run) - Optional\n",
    "\n",
    "Run inference on a few frames to verify the policy works. Skip this section if you want to go straight to deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import av\n",
    "from example_policies.robot_deploy.deploy_core.action_translator import ActionTranslator\n",
    "\n",
    "# Only test on first N frames to save memory\n",
    "NUM_TEST_FRAMES = 5\n",
    "\n",
    "# Prepare action translator\n",
    "action_translator = ActionTranslator(cfg)\n",
    "\n",
    "print(\"Running quick test inference...\")\n",
    "print(f\"Action mode: {action_translator.action_mode}\")\n",
    "print(f\"Testing on first {NUM_TEST_FRAMES} frames...\")\n",
    "\n",
    "# Load parquet data\n",
    "parquet_path = DATASET_DIR / f\"data/chunk-000/episode_{EPISODE_INDEX:06d}.parquet\"\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "# Open video files using PyAV (supports AV1)\n",
    "video_keys = [\"observation.images.rgb_static\", \"observation.images.rgb_left\", \"observation.images.rgb_right\"]\n",
    "video_paths = {\n",
    "    key: DATASET_DIR / f\"videos/chunk-000/{key}/episode_{EPISODE_INDEX:06d}.mp4\"\n",
    "    for key in video_keys\n",
    "}\n",
    "\n",
    "# Create video containers and frame generators\n",
    "video_containers = {}\n",
    "video_streams = {}\n",
    "for key, path in video_paths.items():\n",
    "    if path.exists():\n",
    "        container = av.open(str(path))\n",
    "        video_containers[key] = container\n",
    "        video_streams[key] = container.decode(video=0)\n",
    "        print(f\"‚úÖ Opened: {key}\")\n",
    "\n",
    "# Reset policy\n",
    "policy.reset()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i in range(min(NUM_TEST_FRAMES, len(df))):\n",
    "        row = df.iloc[i]\n",
    "        \n",
    "        # State from parquet - handle both scalar and array columns\n",
    "        state_cols = sorted([c for c in df.columns if c.startswith(\"observation.state\")])\n",
    "        state_values = []\n",
    "        for c in state_cols:\n",
    "            val = row[c]\n",
    "            if isinstance(val, np.ndarray):\n",
    "                state_values.extend(val.flatten().tolist())\n",
    "            else:\n",
    "                state_values.append(float(val))\n",
    "        state = torch.tensor(state_values, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        obs = {\"observation.state\": state}\n",
    "        \n",
    "        # Images from video using PyAV\n",
    "        for key in video_streams:\n",
    "            try:\n",
    "                frame = next(video_streams[key])\n",
    "                # Convert to numpy RGB array, normalize to [0,1], reshape to (C,H,W)\n",
    "                img = frame.to_ndarray(format=\"rgb24\")\n",
    "                img_tensor = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "                obs[key] = img_tensor.unsqueeze(0).to(device)\n",
    "            except StopIteration:\n",
    "                print(f\"  ‚ö†Ô∏è {key}: ran out of frames\")\n",
    "        \n",
    "        # Get policy prediction\n",
    "        raw_action = policy.select_action(obs)\n",
    "        \n",
    "        # Get ground truth action\n",
    "        action_cols = sorted([c for c in df.columns if c.startswith(\"action\")])\n",
    "        gt_action = np.array([float(row[c]) for c in action_cols], dtype=np.float32)\n",
    "        \n",
    "        print(f\"\\nFrame {i}:\")\n",
    "        print(f\"  GT action[0:3]:   {gt_action[:3].tolist()}\")\n",
    "        print(f\"  Pred action[0:3]: {raw_action[0, :3].tolist()}\")\n",
    "\n",
    "# Cleanup\n",
    "for container in video_containers.values():\n",
    "    container.close()\n",
    "\n",
    "print(f\"\\n‚úÖ Test complete! Policy is working.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d069773",
   "metadata": {},
   "source": [
    "## 5. (Optional) Visualize Ground Truth Actions\n",
    "\n",
    "Preview what the ground truth actions look like for this episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load parquet (already have it from section 4, but reload to be safe)\n",
    "parquet_path = DATASET_DIR / f\"data/chunk-000/episode_{EPISODE_INDEX:06d}.parquet\"\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "# Extract actions\n",
    "action_cols = sorted([c for c in df.columns if c.startswith(\"action\")])\n",
    "gt_stack = df[action_cols].values\n",
    "\n",
    "# Create time array\n",
    "times = np.arange(len(gt_stack)) / 10.0  # Assuming 10 fps\n",
    "\n",
    "# Get action names from column names (strip \"action.\" prefix)\n",
    "action_names = [c.replace(\"action.\", \"\") for c in action_cols]\n",
    "\n",
    "D = gt_stack.shape[1]\n",
    "\n",
    "fig, axes = plt.subplots(D, 1, figsize=(14, 2 * D), sharex=True)\n",
    "if D == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for d in range(D):\n",
    "    ax = axes[d]\n",
    "    ax.plot(times, gt_stack[:, d], label=\"Ground Truth\", alpha=0.8)\n",
    "    ax.set_ylabel(action_names[d] if d < len(action_names) else f\"dim {d}\", fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[0].set_title(f\"Episode {EPISODE_INDEX}: Ground Truth Actions\")\n",
    "axes[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Visualized {len(gt_stack)} frames, {D} action dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f4230",
   "metadata": {},
   "source": [
    "## 6. Connect to Robot\n",
    "\n",
    "Establish connection to the robot service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "from example_policies.robot_deploy.robot_io.robot_service import robot_service_pb2_grpc\n",
    "from example_policies.robot_deploy.robot_io.robot_interface import RobotInterface\n",
    "from example_policies.robot_deploy.robot_io.robot_client import RobotClient\n",
    "\n",
    "# Connect to robot\n",
    "print(f\"Connecting to robot at {SERVER_ENDPOINT}...\")\n",
    "channel = grpc.insecure_channel(SERVER_ENDPOINT)\n",
    "stub = robot_service_pb2_grpc.RobotServiceStub(channel)\n",
    "\n",
    "# Create robot interface\n",
    "robot_interface = RobotInterface(stub, cfg)\n",
    "\n",
    "# Test connection by getting a snapshot\n",
    "try:\n",
    "    obs = robot_interface.get_observation(device, show=False)\n",
    "    if obs:\n",
    "        print(\"‚úÖ Connected to robot!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Connected but no observation received\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49c58f",
   "metadata": {},
   "source": [
    "## 7. (Optional) Move Robot to Home Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f292679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move robot to home position\n",
    "try:\n",
    "    response = robot_interface.move_home()\n",
    "    print(f\"‚úÖ Robot homing command sent\")\n",
    "    print(f\"   Response: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Homing failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25777576",
   "metadata": {},
   "source": [
    "## 7.5 Debug: Compare Dataset vs Live Observations\n",
    "\n",
    "Compare the format of observations from the dataset vs live robot to identify mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get one frame from dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OBSERVATION (from parquet + video)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load first frame from parquet\n",
    "parquet_path = DATASET_DIR / f\"data/chunk-000/episode_{EPISODE_INDEX:06d}.parquet\"\n",
    "df = pd.read_parquet(parquet_path)\n",
    "row = df.iloc[0]\n",
    "\n",
    "# State\n",
    "state_cols = sorted([c for c in df.columns if c.startswith(\"observation.state\")])\n",
    "state_values = []\n",
    "for c in state_cols:\n",
    "    val = row[c]\n",
    "    if isinstance(val, np.ndarray):\n",
    "        state_values.extend(val.flatten().tolist())\n",
    "    else:\n",
    "        state_values.append(float(val))\n",
    "dataset_state = torch.tensor(state_values, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "print(f\"\\nobservation.state:\")\n",
    "print(f\"  Shape: {dataset_state.shape}\")\n",
    "print(f\"  Dtype: {dataset_state.dtype}\")\n",
    "print(f\"  Range: [{dataset_state.min():.4f}, {dataset_state.max():.4f}]\")\n",
    "print(f\"  First 5 values: {dataset_state[0, :5].tolist()}\")\n",
    "\n",
    "# Images from video\n",
    "video_keys = [\"observation.images.rgb_static\", \"observation.images.rgb_left\", \"observation.images.rgb_right\"]\n",
    "dataset_images = {}\n",
    "\n",
    "for key in video_keys:\n",
    "    video_path = DATASET_DIR / f\"videos/chunk-000/{key}/episode_{EPISODE_INDEX:06d}.mp4\"\n",
    "    if video_path.exists():\n",
    "        container = av.open(str(video_path))\n",
    "        frame = next(container.decode(video=0))\n",
    "        img = frame.to_ndarray(format=\"rgb24\")\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "        dataset_images[key] = img_tensor.unsqueeze(0).to(device)\n",
    "        container.close()\n",
    "        \n",
    "        print(f\"\\n{key}:\")\n",
    "        print(f\"  Shape: {dataset_images[key].shape}\")\n",
    "        print(f\"  Dtype: {dataset_images[key].dtype}\")\n",
    "        print(f\"  Range: [{dataset_images[key].min():.4f}, {dataset_images[key].max():.4f}]\")\n",
    "        print(f\"  Mean per channel (RGB): {dataset_images[key][0].mean(dim=(1,2)).tolist()}\")\n",
    "\n",
    "# Get live observation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LIVE OBSERVATION (from robot)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "live_obs = robot_interface.get_observation(device, show=False)\n",
    "\n",
    "if live_obs:\n",
    "    # Check state\n",
    "    if \"observation.state\" in live_obs:\n",
    "        live_state = live_obs[\"observation.state\"]\n",
    "        print(f\"\\nobservation.state:\")\n",
    "        print(f\"  Shape: {live_state.shape}\")\n",
    "        print(f\"  Dtype: {live_state.dtype}\")\n",
    "        print(f\"  Range: [{live_state.min():.4f}, {live_state.max():.4f}]\")\n",
    "        print(f\"  First 5 values: {live_state[0, :5].tolist()}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è observation.state NOT FOUND in live obs\")\n",
    "        print(f\"  Available keys: {list(live_obs.keys())}\")\n",
    "    \n",
    "    # Check images\n",
    "    for key in video_keys:\n",
    "        if key in live_obs:\n",
    "            live_img = live_obs[key]\n",
    "            print(f\"\\n{key}:\")\n",
    "            print(f\"  Shape: {live_img.shape}\")\n",
    "            print(f\"  Dtype: {live_img.dtype}\")\n",
    "            print(f\"  Range: [{live_img.min():.4f}, {live_img.max():.4f}]\")\n",
    "            print(f\"  Mean per channel (RGB): {live_img[0].mean(dim=(1,2)).tolist()}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è {key} NOT FOUND in live obs\")\n",
    "    \n",
    "    # Show all available keys\n",
    "    print(f\"\\n\\nAll live obs keys: {list(live_obs.keys())}\")\n",
    "else:\n",
    "    print(\"‚ùå No observation received from robot\")\n",
    "\n",
    "# Visual comparison - show images side by side\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VISUAL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if live_obs:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    for i, key in enumerate(video_keys):\n",
    "        # Dataset image\n",
    "        if key in dataset_images:\n",
    "            img_np = dataset_images[key][0].cpu().permute(1, 2, 0).numpy()\n",
    "            axes[0, i].imshow(img_np)\n",
    "            axes[0, i].set_title(f\"Dataset: {key.split('.')[-1]}\")\n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Live image\n",
    "        if key in live_obs:\n",
    "            img_np = live_obs[key][0].cpu().permute(1, 2, 0).numpy()\n",
    "            # Clip to valid range for display\n",
    "            img_np = np.clip(img_np, 0, 1)\n",
    "            axes[1, i].imshow(img_np)\n",
    "            axes[1, i].set_title(f\"Live: {key.split('.')[-1]}\")\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Check policy's expected input features\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"POLICY EXPECTED INPUT FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nImage features expected by policy: {cfg.image_features}\")\n",
    "print(f\"\\nAll input features:\")\n",
    "for key, feature in cfg.input_features.items():\n",
    "    print(f\"  {key}: shape={feature.shape}\")\n",
    "\n",
    "# Check normalization stats\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NORMALIZATION STATS (from training)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if hasattr(policy, 'normalize_inputs') and hasattr(policy.normalize_inputs, 'stats') and policy.normalize_inputs.stats is not None:\n",
    "    for key, stats in policy.normalize_inputs.stats.items():\n",
    "        print(f\"\\n{key}:\")\n",
    "        if hasattr(stats, 'mean') and stats.mean is not None:\n",
    "            mean_vals = stats.mean.flatten()[:5].tolist() if stats.mean.numel() > 5 else stats.mean.flatten().tolist()\n",
    "            print(f\"  Mean (first 5): {mean_vals}\")\n",
    "        if hasattr(stats, 'std') and stats.std is not None:\n",
    "            std_vals = stats.std.flatten()[:5].tolist() if stats.std.numel() > 5 else stats.std.flatten().tolist()\n",
    "            print(f\"  Std (first 5): {std_vals}\")\n",
    "else:\n",
    "    print(\"Could not access normalization stats (stats is None or not available)\")\n",
    "\n",
    "# Compare shapes and ranges\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if live_obs:\n",
    "    # State comparison\n",
    "    if \"observation.state\" in live_obs:\n",
    "        print(f\"\\nState shape match: {dataset_state.shape == live_obs['observation.state'].shape}\")\n",
    "        if dataset_state.shape != live_obs['observation.state'].shape:\n",
    "            print(f\"  Dataset: {dataset_state.shape}, Live: {live_obs['observation.state'].shape}\")\n",
    "    \n",
    "    # Image comparison\n",
    "    for key in video_keys:\n",
    "        if key in live_obs and key in dataset_images:\n",
    "            shape_match = dataset_images[key].shape == live_obs[key].shape\n",
    "            range_diff = abs(dataset_images[key].max().item() - live_obs[key].max().item())\n",
    "            mean_diff = abs(dataset_images[key].mean().item() - live_obs[key].mean().item())\n",
    "            \n",
    "            print(f\"\\n{key}:\")\n",
    "            print(f\"  Shape match: {shape_match}\")\n",
    "            if not shape_match:\n",
    "                print(f\"    Dataset: {dataset_images[key].shape}, Live: {live_obs[key].shape}\")\n",
    "            print(f\"  Max diff: {range_diff:.4f}\")\n",
    "            print(f\"  Mean diff: {mean_diff:.4f}\")\n",
    "            print(f\"    Dataset max: {dataset_images[key].max():.4f}, Live max: {live_obs[key].max():.4f}\")\n",
    "            print(f\"    Dataset mean: {dataset_images[key].mean():.4f}, Live mean: {live_obs[key].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c22ea5",
   "metadata": {},
   "source": [
    "## 8. Deploy: Send Actions to Robot\n",
    "\n",
    "‚ö†Ô∏è **This will move the robot!** Make sure the workspace is clear.\n",
    "\n",
    "This cell replays the episode using observations from the dataset and sends the policy's predicted actions to the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8aeeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import av\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from example_policies.robot_deploy.deploy_core.action_translator import ActionTranslator\n",
    "from example_policies.utils.action_order import ActionMode\n",
    "\n",
    "# Controller mode\n",
    "CONTROLLER = RobotClient.CART_WAYPOINT  # Most stable\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚ö†Ô∏è  ROBOT DEPLOYMENT FROM DATASET OBSERVATIONS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Episode: {EPISODE_INDEX}\")\n",
    "print(f\"Frames: {len(episode_indices)}\")\n",
    "print(f\"Frequency: {INFERENCE_FREQUENCY_HZ} Hz\")\n",
    "print(f\"Controller: {CONTROLLER}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nThis uses RECORDED observations from the dataset as policy input,\")\n",
    "print(\"but sends the PREDICTED actions to the robot.\")\n",
    "\n",
    "# Load parquet data for state (small, can stay in memory)\n",
    "print(\"\\nLoading episode state data from parquet...\")\n",
    "parquet_path = DATASET_DIR / f\"data/chunk-000/episode_{EPISODE_INDEX:06d}.parquet\"\n",
    "df = pd.read_parquet(parquet_path)\n",
    "print(f\"‚úÖ Loaded {len(df)} frames from parquet\")\n",
    "\n",
    "# Get video paths\n",
    "video_keys = [\"observation.images.rgb_static\", \"observation.images.rgb_left\", \"observation.images.rgb_right\"]\n",
    "video_paths = {\n",
    "    key: DATASET_DIR / f\"videos/chunk-000/{key}/episode_{EPISODE_INDEX:06d}.mp4\"\n",
    "    for key in video_keys\n",
    "}\n",
    "\n",
    "# Open video files using PyAV (supports AV1)\n",
    "print(\"Opening video files...\")\n",
    "video_containers = {}\n",
    "video_streams = {}\n",
    "for key, path in video_paths.items():\n",
    "    if path.exists():\n",
    "        container = av.open(str(path))\n",
    "        video_containers[key] = container\n",
    "        video_streams[key] = container.decode(video=0)\n",
    "        print(f\"  ‚úÖ {key}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {key} not found\")\n",
    "\n",
    "confirm = input(\"\\nType 'yes' to start deployment: \")\n",
    "if confirm.lower() != 'yes':\n",
    "    print(\"Deployment cancelled.\")\n",
    "    for container in video_containers.values():\n",
    "        container.close()\n",
    "else:\n",
    "    print(\"\\nüöÄ Starting deployment...\")\n",
    "    \n",
    "    # Reset policy and action translator\n",
    "    policy.reset()\n",
    "    action_translator = ActionTranslator(cfg)\n",
    "    \n",
    "    period = 1.0 / INFERENCE_FREQUENCY_HZ\n",
    "    \n",
    "    try:\n",
    "        for i in range(len(df)):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Build observation from parquet + video\n",
    "            row = df.iloc[i]\n",
    "            \n",
    "            # State from parquet - handle both scalar and array columns\n",
    "            state_cols = sorted([c for c in df.columns if c.startswith(\"observation.state\")])\n",
    "            state_values = []\n",
    "            for c in state_cols:\n",
    "                val = row[c]\n",
    "                if isinstance(val, np.ndarray):\n",
    "                    state_values.extend(val.flatten().tolist())\n",
    "                else:\n",
    "                    state_values.append(float(val))\n",
    "            state = torch.tensor(state_values, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            \n",
    "            obs = {\"observation.state\": state}\n",
    "            \n",
    "            # Images from video using PyAV\n",
    "            for key in video_streams:\n",
    "                try:\n",
    "                    frame = next(video_streams[key])\n",
    "                    img = frame.to_ndarray(format=\"rgb24\")\n",
    "                    img_tensor = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "                    obs[key] = img_tensor.unsqueeze(0).to(device)\n",
    "                except StopIteration:\n",
    "                    print(f\"  ‚ö†Ô∏è {key}: ran out of frames at {i}\")\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                # Get policy prediction\n",
    "                raw_action = policy.select_action(obs)\n",
    "                \n",
    "                # Translate to robot command\n",
    "                robot_action = action_translator.translate(raw_action, obs)\n",
    "            \n",
    "            # Send to robot\n",
    "            robot_interface.send_action(\n",
    "                robot_action,\n",
    "                action_translator.action_mode,\n",
    "                CONTROLLER\n",
    "            )\n",
    "            \n",
    "            # Clear tensors\n",
    "            del obs, raw_action, robot_action\n",
    "            \n",
    "            # Progress\n",
    "            if i % 10 == 0:\n",
    "                print(f\"  Frame {i+1}/{len(df)}\")\n",
    "            \n",
    "            # Wait for next cycle\n",
    "            elapsed = time.time() - start_time\n",
    "            sleep_time = max(0.0, period - elapsed)\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Deployment complete! Sent {len(df)} actions from dataset observations.\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è Deployment interrupted by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during deployment: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Close video containers\n",
    "        for container in video_containers.values():\n",
    "            container.close()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add1978",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the gRPC channel\n",
    "channel.close()\n",
    "print(\"Connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
